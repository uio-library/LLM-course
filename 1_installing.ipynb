{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b0f5c9-8070-44b8-b1ea-c0a337d373ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Installing Software\n",
    "\n",
    "We'll use [LangChain](https://www.langchain.com/), an open-source library for making applications with LLMs.\n",
    "We'll use models from [HuggingFace](https://huggingface.co/), a website that has tools and models for machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a041d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## General LLM Software\n",
    "We will install LangChain and HuggingFace software first.\n",
    "Transformers is the basic technology used in large language models,\n",
    "so we install the library `sentence-transformers` as well.\n",
    "Models use the `sentencepiece` library, so we'll need that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2657ee1-097c-467a-b5e0-ccc67eb3e542",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip huggingface-hub langchain langchain-community langchain-huggingface sentence-transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c732dd7-6202-436a-9aa5-e84cd1266f51",
   "metadata": {},
   "source": [
    "##  Software for Reading Text Documents\n",
    "We will use [unstructured](https://unstructured.io/) for reading documents. Unstructured supports different document formats, like PDFs, Word files and plain text documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259d478-21b2-4d61-9fbb-4fc4070d5874",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade unstructured[all-docs] langchain-unstructured pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c13af-d471-4de3-a415-57d83c60ac67",
   "metadata": {},
   "source": [
    "## Search Index\n",
    "For the [RAG chapter](RAG) we will use [FAISS](https://faiss.ai/) to search for documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a25453-ea0b-40d4-8f68-5a6337a4bd41",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd6342-35c2-415b-b4c9-b0f69fad3896",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## The Language Model\n",
    "We'll use models from [HuggingFace](https://huggingface.co/), a website that has tools and models for machine learning.\n",
    "We'll use the open-weights LLM \n",
    "[mistralai/Ministral-8B-Instruct-2410](https://huggingface.co/mistralai/Ministral-8B-Instruct-2410)\n",
    "for most of our tasks.\n",
    "This model has 8 billion parameters.\n",
    "For comparison, one of the largest LLMs at the time of writing is Llama 3.1, with 405 billion parameters.\n",
    "Still, Ministral-8B-Instruct-2410 is around 16 GB, which makes it a quite large model.\n",
    "To run it, we must have a GPU with at least 20 GB memory.\n",
    "It can also be run without a GPU, but that will be much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb96fff-c25b-4d19-a6b5-83b247d6591c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%env HF_HOME=/fp/projects01/ec443/huggingface/cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd74d3d-d6b3-422e-ba7f-160036830e38",
   "metadata": {},
   "source": [
    "```{admonition} Optional\n",
    "\n",
    "If you’re running one of the models that is *already downloaded* Educloud/Fox project ec443 the model, you can skip this step.\n",
    "If you’re not running on Educloud/Fox project ec443 or want to use a model that isn't already downloaded, you’ll need to download the model.\n",
    "\n",
    "You will need a *User Access Token* from HuggingFace.\n",
    "If you don't already have  a user account on HuggingFace, you must first sign up for one.\n",
    "Click the button  \"Sign Up\"  in the upper right corner on \n",
    "[HuggingFace](https://huggingface.co/).\n",
    "\n",
    "When you have logged in to HuggingFace with your user account, \n",
    "you can create a \n",
    "[User Access Token](https://huggingface.co/settings/tokens)\n",
    "giving *read* access\n",
    "by following this [guide](https://huggingface.co/docs/hub/en/security-tokens).\n",
    "\n",
    "    from huggingface_hub import login\n",
    "    login()\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
